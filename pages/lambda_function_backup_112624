import json
import boto3
import pprint
import base64
import langchain
from langchain.llms.bedrock import Bedrock
from botocore.client import Config
from langchain.prompts import PromptTemplate
import re
import random

# pp = pprint.PrettyPrinter(indent=2)
session = boto3.session.Session()
region = session.region_name
# print('region.....:',region) # us-east-1
# region = 'us-west-2'
print('region.....:',region)
bedrock_config = Config(connect_timeout=120, read_timeout=120, retries={'max_attempts': 0})
bedrock_client = boto3.client('bedrock-runtime', region_name = region)
bedrock_agent_client = boto3.client("bedrock-agent-runtime",config=bedrock_config, region_name = region)

polly_client = boto3.client('polly')
s3_client = boto3.client('s3')
S3_BUCKET = 'wonderstorytexttoaudiofile'
language_code = "en"

# "Vietnamese", # "Tagalog", # "Urdu" - this languages are not avilable

def get_language_code(language):
    voice_map = {
        "English": "en",
        "Spanish": "es",
        "French": "fr",
        "German": "de",
        "Japanese": "ja",
        "Hindi":"hi",
        "Mandarin":"cmn",
        "Arabic":"arb",
        "Italian":"it"
    }
    return voice_map.get(language, "Joanna")
 
def get_polly_voice(language_code):
 
    voice_map = {
        "en": "Joanna", # English
        "es": "Lucia", # Spanish
        "fr": "Celine", # French
        "de": "Hans", # German
        "ja": "Mizuki", # Japanese
        "hi": "Aditi", # Hindi
        "cmn":"Zhiyu", # Mandarin
        "arb":"Zeina", # Arabic
        "it":"Carla" # Italian
    }
    return voice_map.get(language_code, "Joanna")

# This function take the input in the text format and geneate the audio and save it into S3 and return the file name.
# Refer polly documentation
def generate_audio(index, text, language_code):
    response = polly_client.synthesize_speech(
        Text=text,
        OutputFormat='mp3',
        VoiceId=get_polly_voice(language_code)
    )
 
# creating an audio file on S3 in the mp3 format
    audio_file_name = str(index)+"_"+"story_audio.mp3"
    s3_client.put_object(
        Bucket=S3_BUCKET,
        Key=audio_file_name,
        Body=response['AudioStream'].read()
    )
 
    #audio_url = f"https://{S3_BUCKET}.s3.amazonaws.com/{audio_file_name}"

    return audio_file_name
 
# This is the function which takes the input as a story text and return story files name 
def getAudioStoryFiles(story_texts,story_lang):
     lang_code = get_language_code(story_lang)
     story_files = []
     for index, story_text in enumerate(story_texts):
        story_files.append(generate_audio(index,story_text,lang_code))
     return story_files

 
def getStory(event):
    # event = json.loads(event['body'])
    # story_theme = 'children'
    # story_type = 'children'
    # main_character  = 'Laila'
    # story_theme = 'Brushing the tooth'
    # moral_lesson = 'develop hygiene practices'
    # setting  = 'megical kingdom'
    # word_count = '300'
    # story_lang = 'English'
    character_type = event['character_type']
    age = event['age']
    height = event['height']
    hair_color = event['hair_color']
    eye_color = event['eye_color']
    story_type = event['story_type']
    main_character = event['main_character']
    story_theme = event['story_theme']
    moral_lesson = event['moral_lesson']
    setting = event['setting']
    word_count = event['word_count']
    story_lang = event['story_lang']
    try:
        kbId = "V1XKME5RZW"
        def retrieve(query, kbId, numberOfResults=5):
            return bedrock_agent_client.retrieve(
                retrievalQuery= {
                    'text': query
                },
                knowledgeBaseId=kbId,
                retrievalConfiguration= {
                    'vectorSearchConfiguration': {
                        'numberOfResults': numberOfResults
                    }
                }
            )
        print("Story Theme --> ",story_theme)
        query = story_theme
        response = retrieve(query, kbId, 5)
        retrievalResults = response['retrievalResults']
        # fetch context from the response
        def get_contexts(retrievalResults):
            contexts = []
            for retrievedResult in retrievalResults: 
                contexts.append(retrievedResult['content']['text'])
            return contexts
        contexts = get_contexts(retrievalResults)
        print('line 108...')
        prompt = f""" 
                You are a story creator.  You have been asked to generate a {story_type} story with one of the character name as {main_character} who lives in {setting}. 
                The story should focus on {story_theme} and teach the moral lesson that {moral_lesson}. The language should be simple, engaging, and suitable 
                for {story_type}. Make the story imaginative, with playful elements, and include a happy ending where the {main_character} learns 
                a valuable lesson. Please create the story with {word_count} words Story theme is inclosed in the <question> tag. Story should be in the language as {story_lang}.
                
                <context> 
                {contexts} 
                </context> 
                
                <question> 
                {query} 
                </question> 

                Give response in Json format by following below instruction,
                    1) Divide the story into seven equal parts and use the following instructions to generate a response.
                    2) Each object in JSON should contain two keys: stroy_text and caption. Don't give the object any name or number.
                    3) story_text should contain story text.
                    4) Generate captions tailored for use as prompts with a stable diffusion model. Ensure the captions align with the story, exclude any filtered words, and keep the main character consistent. Captions should describe the character's appearance and setting in detail, suitable for creating animated images without incorporating text into the visuals.
                    5) Inclose the JSON only with Curly Brackets.
                    6) Only return JSON, not any additional text & new line in response.
        \n\nAssistant:"""
        
        print('line 131...')
        # Creating a message with prompt to invoke LLM
        messages=[{ "role":'user', "content":[{'type':'text','text': prompt.format(contexts, query)}]}]
        sonnet_payload = json.dumps({
            "anthropic_version": "bedrock-2023-05-31",
            "max_tokens": 2500,
            "messages": messages,
            "temperature": 0.5,
            "top_p": 1
                }  )
        modelId = 'anthropic.claude-3-haiku-20240307-v1:0' 
        accept = 'application/json'
        contentType = 'application/json'
        
        print('line 145...')
        # Invoke LLM which is returing the response
        response = bedrock_client.invoke_model(body=sonnet_payload, modelId=modelId, accept=accept, contentType=contentType)
        # print('region2...',region2)
        # response = new_llm_client.invoke_model(body=sonnet_payload, modelId=modelId, accept=accept, contentType=contentType)
        response_body = json.loads(response.get('body').read())
        response_text = response_body.get('content')[0]['text']
        print('line 153...')
        # Creating a json object by adding square bracket
        json_string = "[" + response_text + "]"

        # creating a json object
        objects_list = json.loads(json_string)

        story_texts = [obj['story_text'] for obj in objects_list]
        captions = [obj['caption'] for obj in objects_list]

        print('line 163...')
        storyfiles = getAudioStoryFiles(story_texts,story_lang)
 
        data = {}
        data['story_texts'] = story_texts
        data['captions'] = captions
        data['storyfiles'] = storyfiles
        # print("after data list creations............")
        json_data = json.dumps(data)
        #print("json data -- ", json_data)
        
    except Exception as e:
        print(f"Error generating the code: {e}")
        return ""
    return {
        "statusCode": 200,
        "body": json_data
    }
 
# this method is for generating image from stability.stable-diffusion-xl-v1 model
def getImage(character_type,age,height,hair_color,eye_color,story_prompt, previous_prompt):
    # character_type = character_type
    # age = age
    # height = height
    # hair_color = hair_color
    # eye_color = eye_color
    try:
        stability_model_id = "stability.stable-diffusion-xl-v1"
        base64_image_data1=""
        # base64_image_data2=""
 
        # prompt = "Create an animated image based on prompt. " +  story_prompt 
        
        # prompt1 = prompt + ". Ensure that the character image is algined between " prompt + "and" + previous_prompt
        prompt =  story_prompt 
        # prompt1 = "Create an animated image based on prompt " + prompt + ". Ensure that the character image is algined between " + prompt + "and" + previous_prompt
        character_feature = f". Main character's age should be {age} years old, height and build of the main character should be {height} and hair color should be {hair_color} and eye color should be {eye_color}."
        print(character_feature)

        if character_type == 'Human-Centric Stories':
            prompt1 = "Create an animated image based on prompt " + prompt + ". Ensure that the character image is algined between " + prompt + "and" + previous_prompt + character_feature 
        else:
            prompt1 = "Create an animated image based on prompt " + prompt + ". Ensure that the character image is algined between " + prompt + "and" + previous_prompt
       
        print('Image prompt1....', prompt1)
        native_request1 = {"text_prompts":[{"text":prompt1,"weight":1}],"cfg_scale":10,"steps":50,"seed":123456,"width":1024,"height":1024,"samples":1}
        request1 = json.dumps(native_request1)
        response1 = bedrock_client.invoke_model(modelId=stability_model_id, body=request1)
        model_response1 = json.loads(response1.get("body").read())
        base64_image_data1 = model_response1["artifacts"][0].get("base64")
       
        data = {}
        data['image_data_decode1']  =  base64_image_data1
        # data['image_data_decode2']  =  base64_image_data2

        # print("after data list creations............")
        json_data = json.dumps(data)
        #print("json data -- ", json_data)
    except Exception as e:
        print(f"Error generating the code: {e}")
        data = {}
        data['image_data_decode1']  = "INVALID_PROMPT"
        json_data = json.dumps(data)
        return {
            "statusCode": 200,
            "body": json_data
        }
    return {
        "statusCode": 200,
        "body": json_data
    }

# this method is for generating image from amazon.titan-image-generator-v1 model
def getImage_amazon_titan(story_prompt, previous_prompt):
    try:
        model_id = "amazon.titan-image-generator-v1"
        base64_image_data1=""

        prompt =  story_prompt 
        prompt1 = "Create an animated image based on prompt " + prompt + ". Ensure that the character image is algined between " + prompt + "and" + previous_prompt
        print('prompt1....', prompt1)

        # seed = random.randint(0, 2147483647)
    
        seed = 123456
        random.seed(seed)

        native_request = {
            "taskType": "TEXT_IMAGE",
            "textToImageParams": {"text": prompt1},
            "imageGenerationConfig": {
                "numberOfImages": 1,
                "quality": "standard",
                "cfgScale": 8.0,
                "height": 512,
                "width": 512,
                "seed": seed,
            },
        }

        request1 = json.dumps(native_request)
        response1 = bedrock_client.invoke_model(modelId=model_id, body=request1)
        model_response1 = json.loads(response1["body"].read())
        base64_image_data1 = model_response1["images"][0]
       
        data = {}
        data['image_data_decode1']  =  base64_image_data1
        # data['image_data_decode2']  =  base64_image_data2

        # print("after data list creations............")
        json_data = json.dumps(data)
        #print("json data -- ", json_data)
    except Exception as e:
        print(f"Error generating the code: {e}")
        data = {}
        data['image_data_decode1']  = 'INVALID_PROMPT'
        json_data = json.dumps(data)
        return {
            "statusCode": 200,
            "body": json_data
        }
    return {
        "statusCode": 200,
        "body": json_data
    }


def lambda_handler(event, context):
    print("############# In API Call")
    print("event -----> ",event)
    event = json.loads(event['body'])
    api_path = event['api_Path']
 
    #api_path = "getStory"
    print("API Call")
 
    if api_path == 'getStory':
        print("###### Get Story API Call Responce -")
        response = getStory(event)
        print("response....", response)
        return response
    elif api_path == 'getImage':
        print("########## get image call")
        image_event = event['payload']
        character_type = image_event['character_type']
        age = image_event['age']
        height = image_event['height']
        hair_color = image_event['hair_color']
        eye_color = image_event['eye_color']
        story_prompt = event['storyPrompt']
        previous_prompt  = event['previousPrompt']
        
        #method for stability.stable-diffusion
        response = getImage(character_type,age,height,hair_color,eye_color,story_prompt, previous_prompt)
        
        #method for amazon.titan
        #response = getImage_amazon_titan(story_prompt, previous_prompt)

        print("response image ....", response)
        return response
